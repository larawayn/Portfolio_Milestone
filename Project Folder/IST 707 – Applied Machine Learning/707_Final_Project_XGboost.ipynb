{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost according to kaggle is how you solve fashion mnist\n",
    "# https://iryndin.dev/post/xgboost_fashion_mnist/\n",
    "# https://github.com/anktplwl91/fashion_mnist/blob/master/fashion_xgboost.ipynb\n",
    "# https://www.kaggle.com/subhayan2018/exploring-xgboost-with-fashion-mnist\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "import mnist_reader\n",
    "x_train, y_train = mnist_reader.load_mnist('fashion', kind='train')\n",
    "x_test, y_test = mnist_reader.load_mnist('fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) <class 'numpy.ndarray'>\n",
      "(60000,) <class 'numpy.ndarray'>\n",
      "(10000, 784) <class 'numpy.ndarray'>\n",
      "(10000,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, type(x_train))\n",
    "print(y_train.shape, type(y_train))\n",
    "print(x_test.shape, type(x_train))\n",
    "print(y_test.shape, type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"251.453783pt\" version=\"1.1\" viewBox=\"0 0 253.574062 251.453783\" width=\"253.574062pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-05T10:34:59.676653</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 251.453783 \r\nL 253.574062 251.453783 \r\nL 253.574062 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 28.934063 224.69394 \r\nL 246.374063 224.69394 \r\nL 246.374063 7.25394 \r\nL 28.934063 7.25394 \r\nz\r\n\" style=\"fill:#eaeaf2;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pf6d7dbe117)\">\r\n    <image height=\"218\" id=\"image53c0bd596f\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"28.934063\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.69394\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 32.81692 224.69394 \r\nL 32.81692 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(29.758404 242.067533)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 4.15625 35.296875 \r\nQ 4.15625 48 6.765625 55.734375 \r\nQ 9.375 63.484375 14.515625 67.671875 \r\nQ 19.671875 71.875 27.484375 71.875 \r\nQ 33.25 71.875 37.59375 69.546875 \r\nQ 41.9375 67.234375 44.765625 62.859375 \r\nQ 47.609375 58.5 49.21875 52.21875 \r\nQ 50.828125 45.953125 50.828125 35.296875 \r\nQ 50.828125 22.703125 48.234375 14.96875 \r\nQ 45.65625 7.234375 40.5 3 \r\nQ 35.359375 -1.21875 27.484375 -1.21875 \r\nQ 17.140625 -1.21875 11.234375 6.203125 \r\nQ 4.15625 15.140625 4.15625 35.296875 \r\nz\r\nM 13.1875 35.296875 \r\nQ 13.1875 17.671875 17.3125 11.828125 \r\nQ 21.4375 6 27.484375 6 \r\nQ 33.546875 6 37.671875 11.859375 \r\nQ 41.796875 17.71875 41.796875 35.296875 \r\nQ 41.796875 52.984375 37.671875 58.78125 \r\nQ 33.546875 64.59375 27.390625 64.59375 \r\nQ 21.34375 64.59375 17.71875 59.46875 \r\nQ 13.1875 52.9375 13.1875 35.296875 \r\nz\r\n\" id=\"ArialMT-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 71.645491 224.69394 \r\nL 71.645491 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(68.586975 242.067533)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 4.15625 18.75 \r\nL 13.375 19.53125 \r\nQ 14.40625 12.796875 18.140625 9.390625 \r\nQ 21.875 6 27.15625 6 \r\nQ 33.5 6 37.890625 10.78125 \r\nQ 42.28125 15.578125 42.28125 23.484375 \r\nQ 42.28125 31 38.0625 35.34375 \r\nQ 33.84375 39.703125 27 39.703125 \r\nQ 22.75 39.703125 19.328125 37.765625 \r\nQ 15.921875 35.84375 13.96875 32.765625 \r\nL 5.71875 33.84375 \r\nL 12.640625 70.609375 \r\nL 48.25 70.609375 \r\nL 48.25 62.203125 \r\nL 19.671875 62.203125 \r\nL 15.828125 42.96875 \r\nQ 22.265625 47.46875 29.34375 47.46875 \r\nQ 38.71875 47.46875 45.15625 40.96875 \r\nQ 51.609375 34.46875 51.609375 24.265625 \r\nQ 51.609375 14.546875 45.953125 7.46875 \r\nQ 39.0625 -1.21875 27.15625 -1.21875 \r\nQ 17.390625 -1.21875 11.203125 4.25 \r\nQ 5.03125 9.71875 4.15625 18.75 \r\nz\r\n\" id=\"ArialMT-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 110.474063 224.69394 \r\nL 110.474063 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(104.357031 242.067533)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 37.25 0 \r\nL 28.46875 0 \r\nL 28.46875 56 \r\nQ 25.296875 52.984375 20.140625 49.953125 \r\nQ 14.984375 46.921875 10.890625 45.40625 \r\nL 10.890625 53.90625 \r\nQ 18.265625 57.375 23.78125 62.296875 \r\nQ 29.296875 67.234375 31.59375 71.875 \r\nL 37.25 71.875 \r\nz\r\n\" id=\"ArialMT-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 149.302634 224.69394 \r\nL 149.302634 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(143.185603 242.067533)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 188.131205 224.69394 \r\nL 188.131205 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(182.014174 242.067533)scale(0.11 -0.11)\">\r\n       <defs>\r\n        <path d=\"M 50.34375 8.453125 \r\nL 50.34375 0 \r\nL 3.03125 0 \r\nQ 2.9375 3.171875 4.046875 6.109375 \r\nQ 5.859375 10.9375 9.828125 15.625 \r\nQ 13.8125 20.3125 21.34375 26.46875 \r\nQ 33.015625 36.03125 37.109375 41.625 \r\nQ 41.21875 47.21875 41.21875 52.203125 \r\nQ 41.21875 57.421875 37.46875 61 \r\nQ 33.734375 64.59375 27.734375 64.59375 \r\nQ 21.390625 64.59375 17.578125 60.78125 \r\nQ 13.765625 56.984375 13.71875 50.25 \r\nL 4.6875 51.171875 \r\nQ 5.609375 61.28125 11.65625 66.578125 \r\nQ 17.71875 71.875 27.9375 71.875 \r\nQ 38.234375 71.875 44.234375 66.15625 \r\nQ 50.25 60.453125 50.25 52 \r\nQ 50.25 47.703125 48.484375 43.546875 \r\nQ 46.734375 39.40625 42.65625 34.8125 \r\nQ 38.578125 30.21875 29.109375 22.21875 \r\nQ 21.1875 15.578125 18.9375 13.203125 \r\nQ 16.703125 10.84375 15.234375 8.453125 \r\nz\r\n\" id=\"ArialMT-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 226.959777 224.69394 \r\nL 226.959777 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(220.842746 242.067533)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 28.934063 11.136797 \r\nL 246.374063 11.136797 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(13.317031 15.073594)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 28.934063 49.965368 \r\nL 246.374063 49.965368 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(13.317031 53.902165)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 28.934063 88.79394 \r\nL 246.374063 88.79394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 92.730737)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 28.934063 127.622511 \r\nL 246.374063 127.622511 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 131.559308)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 28.934063 166.451083 \r\nL 246.374063 166.451083 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 170.387879)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#pf6d7dbe117)\" d=\"M 28.934063 205.279654 \r\nL 246.374063 205.279654 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 209.216451)scale(0.11 -0.11)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 28.934063 224.69394 \r\nL 28.934063 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 246.374063 224.69394 \r\nL 246.374063 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 28.934063 224.69394 \r\nL 246.374063 224.69394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 28.934063 7.25394 \r\nL 246.374063 7.25394 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pf6d7dbe117\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"28.934063\" y=\"7.25394\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1].reshape((28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new smaller more managable sample set\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 147.9576280117035s\n"
     ]
    }
   ],
   "source": [
    "# log regression on new sample set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "logReg = LogisticRegression(max_iter=2000)\n",
    "logReg.fit(x_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test  = logReg.predict(x_test)\n",
    "prediction_train = logReg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8810333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, prediction_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8441\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=300, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)>\n",
      "Training time: 594.5211815834045s\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(n_estimators=300, n_jobs=-1, seed=0)\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "stop = time.time()\n",
    "print(xgb_clf.get_params)\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9039\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:48:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.5, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)>\n",
      "Training time: 903.4990739822388s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(n_estimators=500, n_jobs=-1, learning_rate=0.5, seed=0)\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "stop = time.time()\n",
    "print(xgb_clf.get_params)\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9053\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=2, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.5, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)>\n",
      "Training time: 1098.3623712062836s\n",
      "test accuracy\n",
      "0.891\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(n_estimators=500, n_jobs=-1, learning_rate=0.5, gamma=2, seed=0)\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "stop = time.time()\n",
    "print(xgb_clf.get_params)\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(\"test accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:21:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_deth\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[11:21:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.5, max_delta_step=0, max_depth=6, max_deth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)>\n",
      "Training time: 864.883885383606s\n",
      "test accuracy\n",
      "0.9053\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(n_estimators=500, n_jobs=-1, learning_rate=0.5, max_deth= 5, min_child_weight= 1, seed=0)\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "stop = time.time()\n",
    "print(xgb_clf.get_params)\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(\"test accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_deth\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-mlogloss:1.02365\n",
      "[1]\tvalidation_0-mlogloss:0.79206\n",
      "[2]\tvalidation_0-mlogloss:0.65773\n",
      "[3]\tvalidation_0-mlogloss:0.57368\n",
      "[4]\tvalidation_0-mlogloss:0.51334\n",
      "[5]\tvalidation_0-mlogloss:0.47138\n",
      "[6]\tvalidation_0-mlogloss:0.44282\n",
      "[7]\tvalidation_0-mlogloss:0.41981\n",
      "[8]\tvalidation_0-mlogloss:0.40298\n",
      "[9]\tvalidation_0-mlogloss:0.39098\n",
      "[10]\tvalidation_0-mlogloss:0.37932\n",
      "[11]\tvalidation_0-mlogloss:0.37105\n",
      "[12]\tvalidation_0-mlogloss:0.36462\n",
      "[13]\tvalidation_0-mlogloss:0.35842\n",
      "[14]\tvalidation_0-mlogloss:0.35319\n",
      "[15]\tvalidation_0-mlogloss:0.34864\n",
      "[16]\tvalidation_0-mlogloss:0.34593\n",
      "[17]\tvalidation_0-mlogloss:0.34225\n",
      "[18]\tvalidation_0-mlogloss:0.33998\n",
      "[19]\tvalidation_0-mlogloss:0.33681\n",
      "[20]\tvalidation_0-mlogloss:0.33468\n",
      "[21]\tvalidation_0-mlogloss:0.33217\n",
      "[22]\tvalidation_0-mlogloss:0.32969\n",
      "[23]\tvalidation_0-mlogloss:0.32843\n",
      "[24]\tvalidation_0-mlogloss:0.32596\n",
      "[25]\tvalidation_0-mlogloss:0.32537\n",
      "[26]\tvalidation_0-mlogloss:0.32398\n",
      "[27]\tvalidation_0-mlogloss:0.32278\n",
      "[28]\tvalidation_0-mlogloss:0.32185\n",
      "[29]\tvalidation_0-mlogloss:0.32042\n",
      "[30]\tvalidation_0-mlogloss:0.31948\n",
      "[31]\tvalidation_0-mlogloss:0.31827\n",
      "[32]\tvalidation_0-mlogloss:0.31750\n",
      "[33]\tvalidation_0-mlogloss:0.31589\n",
      "[34]\tvalidation_0-mlogloss:0.31493\n",
      "[35]\tvalidation_0-mlogloss:0.31427\n",
      "[36]\tvalidation_0-mlogloss:0.31354\n",
      "[37]\tvalidation_0-mlogloss:0.31217\n",
      "[38]\tvalidation_0-mlogloss:0.31193\n",
      "[39]\tvalidation_0-mlogloss:0.31070\n",
      "[40]\tvalidation_0-mlogloss:0.31065\n",
      "[41]\tvalidation_0-mlogloss:0.31073\n",
      "[42]\tvalidation_0-mlogloss:0.31041\n",
      "[43]\tvalidation_0-mlogloss:0.30976\n",
      "[44]\tvalidation_0-mlogloss:0.30933\n",
      "[45]\tvalidation_0-mlogloss:0.30863\n",
      "[46]\tvalidation_0-mlogloss:0.30855\n",
      "[47]\tvalidation_0-mlogloss:0.30784\n",
      "[48]\tvalidation_0-mlogloss:0.30741\n",
      "[49]\tvalidation_0-mlogloss:0.30734\n",
      "[50]\tvalidation_0-mlogloss:0.30747\n",
      "[51]\tvalidation_0-mlogloss:0.30727\n",
      "[52]\tvalidation_0-mlogloss:0.30714\n",
      "[53]\tvalidation_0-mlogloss:0.30762\n",
      "[54]\tvalidation_0-mlogloss:0.30773\n",
      "[55]\tvalidation_0-mlogloss:0.30763\n",
      "[56]\tvalidation_0-mlogloss:0.30769\n",
      "[57]\tvalidation_0-mlogloss:0.30795\n",
      "[58]\tvalidation_0-mlogloss:0.30821\n",
      "[59]\tvalidation_0-mlogloss:0.30787\n",
      "[60]\tvalidation_0-mlogloss:0.30881\n",
      "[61]\tvalidation_0-mlogloss:0.30944\n",
      "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.5, max_delta_step=0, max_depth=6, max_deth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)>\n",
      "Training time: 134.84747076034546s\n",
      "test accuracy\n",
      "0.8887\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(n_estimators=500, n_jobs=-1, learning_rate=0.5, max_deth= 5, min_child_weight= 1, seed=0)\n",
    "xgb_clf.fit(x_train,y_train,eval_metric='mlogloss', early_stopping_rounds = 10, eval_set = [(x_test, y_test)])\n",
    "stop = time.time()\n",
    "print(xgb_clf.get_params)\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(\"test accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conwa\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[20:22:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"max_deth\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[20:22:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "<bound method XGBModel.get_params of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.5, max_delta_step=0, max_depth=6, max_deth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=500, n_jobs=-1, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=20, scale_pos_weight=None, seed=0, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)>\n",
      "Training time: 1003.9195713996887s\n",
      "test accuracy\n",
      "0.9041\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(n_estimators=500, n_jobs=-1, learning_rate=0.5, max_deth= 5, min_child_weight= 1, reg_lambda =20, seed=0)\n",
    "xgb_clf.fit(x_train,y_train)\n",
    "stop = time.time()\n",
    "print(xgb_clf.get_params)\n",
    "print(f\"Training time: {stop - start}s\")\n",
    "y_pred = xgb_clf.predict(x_test)\n",
    "print(\"test accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd047ff93630845832aa870c496f8afc95e13ee7dba6d6ab380b05e676515cddff0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
